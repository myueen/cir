{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SingleCellRNA dataset regression (accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unzip the 'pbmc_1_counts.csv.zip' to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install contrastive-inverse-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import contrastive_inverse_regression\n",
    "from contrastive_inverse_regression import CIR\n",
    "\n",
    "# first unzip 'pbmc_1_counts.csv.zip'\n",
    "data = pd.read_csv('pbmc_1_counts.csv')\n",
    "data = data.iloc[:, 1:]\n",
    "data = data.transpose()\n",
    "\n",
    "cell_type = pd.read_csv('pbmc_1_cell_type.csv')\n",
    "cell_type = cell_type.iloc[:, 1].values\n",
    "\n",
    "# foreground data\n",
    "fg = data.dropna()\n",
    "\n",
    "p = 100     # p can vary from 100 to 500\n",
    "\n",
    "# select the top p highly variable genes\n",
    "col_var = np.var(fg, axis=0)\n",
    "col_var_sorted_idx = np.argsort(-col_var)\n",
    "fg = fg.iloc[:, col_var_sorted_idx[:p]]\n",
    "\n",
    "# foreground label: cell types\n",
    "Y = cell_type\n",
    "Y = pd.Categorical(Y)\n",
    "Y = Y.rename_categories({'B cell': '0', 'CD4 T cell': '1', 'CD8 T cell': '2', 'NK cell': '3',\n",
    "                         'Plasma cell': '4', 'cDC': '5', 'cMono': '6', 'ncMono': '7', 'pDC': '8'})\n",
    "Y = Y.astype(float)\n",
    "labels = np.unique(Y)      # set of unique foreground labels\n",
    "L = len(labels)         # number of foreground classes/slices\n",
    "n = fg.shape[0]  # foreground sample size\n",
    "X = fg - np.mean(fg, axis=0)\n",
    "X = X.values\n",
    "\n",
    "# background data\n",
    "bg = fg\n",
    "m, p = bg.shape  # background sample size\n",
    "Yt = 3 * np.ones((m, 1))  # background labels\n",
    "Yt = np.random.randint(1, 10, size=(m, 1))\n",
    "\n",
    "\n",
    "# tuning parameter\n",
    "alpha = 1.5\n",
    "d = 2\n",
    "\n",
    "# Dimensionality settings\n",
    "Ds = range(2, 11)\n",
    "Accuracy_KNN = []\n",
    "Accuracy_Tree = []\n",
    "Accuracy_boosting = []\n",
    "Accuracy_NN = []\n",
    "\n",
    "for d in Ds:\n",
    "    print(f'd = {d}')\n",
    "\n",
    "    # PCA\n",
    "    print('PCA......')\n",
    "    pca = PCA(n_components=d)\n",
    "    X_PCA = pca.fit_transform(X)\n",
    "\n",
    "    # CPCA\n",
    "    print('CPCA......')\n",
    "    cov_fg = np.cov(fg, rowvar=False)\n",
    "    cov_bg = np.cov(bg, rowvar=False)\n",
    "    eigvals, eigvecs = np.linalg.eig(cov_fg - alpha * cov_bg)\n",
    "    idx = eigvals.argsort()[::-1][:d]\n",
    "    V_CPCA = eigvecs[:, idx]\n",
    "    X_CPCA = X @ V_CPCA\n",
    "\n",
    "    # LDA\n",
    "    print('LDA......')\n",
    "    lda = LDA(n_components=d)\n",
    "    X_LDA = lda.fit_transform(X, Y)\n",
    "\n",
    "    # LASSO\n",
    "    print('LASSO......')\n",
    "    lasso = LassoCV().fit(X, Y)\n",
    "    B = lasso.coef_\n",
    "    selected_idx = np.argsort(np.abs(B))[-d:]\n",
    "    X_LASSO = X[:, selected_idx]\n",
    "\n",
    "    # SIR\n",
    "    print('SIR......')\n",
    "    Sigma_XX = np.cov(X, rowvar=False)\n",
    "    Sigma_X = np.zeros((p, p))\n",
    "    for label in labels:\n",
    "        X_curr = X[Y == label]\n",
    "        n_curr = X_curr.shape[0]\n",
    "        mean_diff = np.mean(X_curr, axis=0) - np.mean(X, axis=0)\n",
    "        Sigma_X += np.outer(mean_diff, mean_diff) * n_curr\n",
    "    Sigma_X /= n\n",
    "    eigvals, eigvecs = np.linalg.eig(Sigma_XX, Sigma_X)\n",
    "    idx = eigvals.argsort()[::-1][:d]\n",
    "    V_SIR = eigvecs[:, idx]\n",
    "    X_SIR = X @ V_SIR\n",
    "\n",
    "    # CIR\n",
    "    print('CIR......')\n",
    "    # Assuming CIR is a defined function\n",
    "    V_CIR = CIR(fg, Y, bg, Yt, alpha, d)\n",
    "    X_CIR = X @ V_CIR\n",
    "\n",
    "    T = 10\n",
    "    for t in range(T):\n",
    "        print(f't = {t}')\n",
    "\n",
    "        # KNN\n",
    "        print('Training KNN')\n",
    "        knn = KNeighborsClassifier()\n",
    "        Accuracy_KNN.append([\n",
    "            cross_val_score(knn, fg, Y, cv=10).mean(),\n",
    "            cross_val_score(knn, X_PCA, Y, cv=10).mean(),\n",
    "            cross_val_score(knn, X_CPCA, Y, cv=10).mean(),\n",
    "            cross_val_score(knn, X_LDA, Y, cv=10).mean(),\n",
    "            cross_val_score(knn, X_LASSO, Y, cv=10).mean(),\n",
    "            cross_val_score(knn, X_SIR, Y, cv=10).mean(),\n",
    "            cross_val_score(knn, X_CIR, Y, cv=10).mean()\n",
    "        ])\n",
    "\n",
    "        # Decision Tree\n",
    "        print('Training Decision Tree')\n",
    "        tree = DecisionTreeClassifier()\n",
    "        Accuracy_Tree.append([\n",
    "            cross_val_score(tree, fg, Y, cv=10).mean(),\n",
    "            cross_val_score(tree, X_PCA, Y, cv=10).mean(),\n",
    "            cross_val_score(tree, X_CPCA, Y, cv=10).mean(),\n",
    "            cross_val_score(tree, X_LDA, Y, cv=10).mean(),\n",
    "            cross_val_score(tree, X_LASSO, Y, cv=10).mean(),\n",
    "            cross_val_score(tree, X_SIR, Y, cv=10).mean(),\n",
    "            cross_val_score(tree, X_CIR, Y, cv=10).mean()\n",
    "        ])\n",
    "\n",
    "        # Boosting\n",
    "        print('Training Boosting')\n",
    "        boosting = AdaBoostClassifier()\n",
    "        Accuracy_boosting.append([\n",
    "            cross_val_score(boosting, fg, Y, cv=10).mean(),\n",
    "            cross_val_score(boosting, X_PCA, Y, cv=10).mean(),\n",
    "            cross_val_score(boosting, X_CPCA, Y, cv=10).mean(),\n",
    "            cross_val_score(boosting, X_LDA, Y, cv=10).mean(),\n",
    "            cross_val_score(boosting, X_LASSO, Y, cv=10).mean(),\n",
    "            cross_val_score(boosting, X_SIR, Y, cv=10).mean(),\n",
    "            cross_val_score(boosting, X_CIR, Y, cv=10).mean()\n",
    "        ])\n",
    "\n",
    "        # Neural Network\n",
    "        print('Training Neural Network')\n",
    "        nn = MLPClassifier(max_iter=1000)\n",
    "        Accuracy_NN.append([\n",
    "            cross_val_score(nn, fg, Y, cv=10).mean(),\n",
    "            cross_val_score(nn, X_PCA, Y, cv=10).mean(),\n",
    "            cross_val_score(nn, X_CPCA, Y, cv=10).mean(),\n",
    "            cross_val_score(nn, X_LDA, Y, cv=10).mean(),\n",
    "            cross_val_score(nn, X_LASSO, Y, cv=10).mean(),\n",
    "            cross_val_score(nn, X_SIR, Y, cv=10).mean(),\n",
    "            cross_val_score(nn, X_CIR, Y, cv=10).mean()\n",
    "        ])\n",
    "\n",
    "# Convert lists to arrays for easy manipulation\n",
    "Accuracy_KNN = np.array(Accuracy_KNN)\n",
    "Accuracy_Tree = np.array(Accuracy_Tree)\n",
    "Accuracy_boosting = np.array(Accuracy_boosting)\n",
    "Accuracy_NN = np.array(Accuracy_NN)\n",
    "\n",
    "# Calculate mean accuracy\n",
    "Accuracy_KNN_mean = Accuracy_KNN.mean(axis=0)\n",
    "\n",
    "# Plotting KNN accuracy\n",
    "\n",
    "plt.figure()\n",
    "for j in range(Accuracy_KNN_mean.shape[1]):\n",
    "    plt.plot(Ds, Accuracy_KNN_mean[:, j], linewidth=2)\n",
    "plt.legend(['Raw', 'PCA', 'CPCA', 'LDA', 'LASSO', 'SIR', 'CIR'], fontsize=10)\n",
    "plt.title('KNN Accuracy')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
