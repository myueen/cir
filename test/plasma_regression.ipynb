{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lianama/CIR/contrastive-inverse-regression/testing/cir.py:384: LinAlgWarning: Ill-conditioned matrix (rcond=3.64898e-19): result may not be accurate.\n",
      "  aa = solve(eye2k + (alpha * tau) * VU, VX)\n",
      "/Users/lianama/CIR/contrastive-inverse-regression/testing/cir.py:384: LinAlgWarning: Ill-conditioned matrix (rcond=3.64894e-19): result may not be accurate.\n",
      "  aa = solve(eye2k + (alpha * tau) * VU, VX)\n",
      "/Users/lianama/CIR/contrastive-inverse-regression/testing/cir.py:384: LinAlgWarning: Ill-conditioned matrix (rcond=3.64804e-19): result may not be accurate.\n",
      "  aa = solve(eye2k + (alpha * tau) * VU, VX)\n",
      "/Users/lianama/CIR/contrastive-inverse-regression/testing/cir.py:384: LinAlgWarning: Ill-conditioned matrix (rcond=3.6296e-19): result may not be accurate.\n",
      "  aa = solve(eye2k + (alpha * tau) * VU, VX)\n",
      "/Users/lianama/CIR/contrastive-inverse-regression/testing/cir.py:384: LinAlgWarning: Ill-conditioned matrix (rcond=3.55851e-19): result may not be accurate.\n",
      "  aa = solve(eye2k + (alpha * tau) * VU, VX)\n",
      "/Users/lianama/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/lianama/anaconda3/lib/python3.10/site-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "\n",
      "Results for Scaled Gradient Projection Method \n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "   Obj. function = 3.891533e+05\n",
      "\n",
      "   Gradient norm = 1.229389e+01 \n",
      "\n",
      "   ||X^T*X-I||_F = 4.97e-16\n",
      "\n",
      "   Iteration number = 3000\n",
      "\n",
      "   Cpu time (secs) = 4.3793\n",
      "\n",
      "   Number of evaluation(Obj. func) = 4123\n",
      "\n",
      "Training Linear Model\n",
      "coefficients:  [ 0.122791602837945 10.507565601567029]\n",
      "intercept:  189.8920634920635\n",
      "R-squared:  0.11909860569817732\n",
      "This is MSE:  29407.112593684178\n",
      "======================\n",
      "This is the norm of the difference between VVT from matlab and python\n",
      "0.2960301060769725\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import cir\n",
    "from cir import CIR\n",
    "from importlib import reload\n",
    "reload(cir)\n",
    "\n",
    "\n",
    "data = pd.read_table('Retinol.txt', header=None, delim_whitespace=True)\n",
    "data = data.iloc[:, :]\n",
    "\n",
    "# foreground data \n",
    "fg = data.iloc[:, :12].dropna()\n",
    "\n",
    "# foreground response (continuous)\n",
    "Y = data.iloc[:, 12]\n",
    "n, p = fg.shape  # foreground sample size\n",
    "X = fg - np.mean(fg, axis=0)\n",
    "X = X.values\n",
    "\n",
    "# foreground slices \n",
    "L = 10\n",
    "partition = np.linspace(min(Y), max(Y), L)\n",
    "labels = np.zeros(n)\n",
    "for i in range(n):\n",
    "    labels[i] = max(np.where(Y.iloc[i] >= partition)[0]) + 1\n",
    "\n",
    "# background data \n",
    "bg = data.iloc[:, :12].dropna()\n",
    "m, p = bg.shape     # background sample size\n",
    "\n",
    "# background data\n",
    "Yt = data.iloc[:, 13]\n",
    "Lt = 10\n",
    "partitiont = np.linspace(min(Yt), max(Yt), Lt)\n",
    "labelst = np.zeros(m)\n",
    "for i in range(m):\n",
    "    labelst[i] = max(np.where(Yt.iloc[i] >= partitiont)[0]) + 1\n",
    "\n",
    "d = 2\n",
    "alpha = 0.1\n",
    "\n",
    "\n",
    "V_CIR = CIR(fg,labels,bg,labelst,alpha,d)\n",
    "vvt = V_CIR @ V_CIR.T\n",
    "\n",
    "X_CIR = X @ V_CIR\n",
    "# print(V_CIR[:10, :])\n",
    "\n",
    "print(\"Training Linear Model\")\n",
    "model_CIR_LM = LinearRegression().fit(X_CIR, Y)\n",
    "print(\"coefficients: \", model_CIR_LM.coef_)\n",
    "print(\"intercept: \", model_CIR_LM.intercept_)\n",
    "print(\"R-squared: \", model_CIR_LM.score(X_CIR, Y))\n",
    "\n",
    "Y_pred = model_CIR_LM.predict(X_CIR)\n",
    "MSE_CIR_LM = mean_squared_error(Y, Y_pred)\n",
    "\n",
    "print(\"This is MSE: \", MSE_CIR_LM)\n",
    "\n",
    "m1 = [[0.532599608105052,   0.004620083626876,  -0.000320112347451,  -0.006601571813602,  -0.000499345812859,   0.295110986421280,  -0.005625130202443],\n",
    "   [0.004620083626876,   0.926065049338340,  -0.000978627564536,   0.221573065829260,   0.004981206774528,   0.000999866145938,   0.078676661438859],\n",
    "  [-0.000320112347451,  -0.000978627564536,   0.000001220756928,  -0.000229587592840,  -0.000004953664970,  -0.000175728731562,  -0.000079580448973],\n",
    "  [-0.006601571813602,   0.221573065829260,  -0.000229587592840,   0.053125756655810,   0.001199404003959,  -0.004031287483785,   0.018911493104884],\n",
    "  [-0.000499345812859,   0.004981206774528,  -0.000004953664970,   0.001199404003959,   0.000027309337619,  -0.000285084491660,   0.000429116469334],\n",
    "  [0.295110986421280 ,  0.000999866145938 , -0.000175728731562 , -0.004031287483785 , -0.000285084491660,   0.163522264826441,  -0.003249489741347],\n",
    "  [-0.005625130202443,   0.078676661438859,  -0.000079580448973,   0.018911493104884,   0.000429116469334,  -0.003249489741347,   0.006752208134958],\n",
    "   [0.010839350364305,  -0.064090742373393,   0.000061123442157,  -0.015496025558275,  -0.000355720894400,   0.006114167969579,  -0.005571111050421],\n",
    "  [-0.010753209254731,   0.094933481291968,  -0.000093676693721,   0.022876530750223,   0.000521687418020,  -0.006118397967805,   0.008192214667748],\n",
    "  [-0.282957166594681,  -0.001048554700505,   0.000168586240285,   0.003843755046652,   0.000272859775825,  -0.156787629668804,   0.003108023113917],\n",
    "   [0.015239189508293,  -0.001950955622589,  -0.000006964089265,  -0.000687460621746,  -0.000025502974935,   0.008447474162690,  -0.000338048665003],\n",
    "  [-0.284990767155745,  -0.003305043920851,   0.000172167822695,   0.003333126351607,   0.000262712879579,  -0.157910666507893,   0.002939166922469]]\n",
    "\n",
    "\n",
    "\n",
    "VVt_s = vvt[:12, :7]\n",
    "norm = np.linalg.norm(VVt_s-m1, ord='fro')\n",
    "print(\"======================\")\n",
    "print(\"This is the norm of the difference between VVT from matlab and python\")\n",
    "print(norm)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
