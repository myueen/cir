{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lianama/CIR/contrastive-inverse-regression/testing/cir.py:384: LinAlgWarning: Ill-conditioned matrix (rcond=3.64898e-19): result may not be accurate.\n",
      "  aa = solve(eye2k + (alpha * tau) * VU, VX)\n",
      "/Users/lianama/CIR/contrastive-inverse-regression/testing/cir.py:384: LinAlgWarning: Ill-conditioned matrix (rcond=3.64894e-19): result may not be accurate.\n",
      "  aa = solve(eye2k + (alpha * tau) * VU, VX)\n",
      "/Users/lianama/CIR/contrastive-inverse-regression/testing/cir.py:384: LinAlgWarning: Ill-conditioned matrix (rcond=3.64804e-19): result may not be accurate.\n",
      "  aa = solve(eye2k + (alpha * tau) * VU, VX)\n",
      "/Users/lianama/CIR/contrastive-inverse-regression/testing/cir.py:384: LinAlgWarning: Ill-conditioned matrix (rcond=3.6296e-19): result may not be accurate.\n",
      "  aa = solve(eye2k + (alpha * tau) * VU, VX)\n",
      "/Users/lianama/CIR/contrastive-inverse-regression/testing/cir.py:384: LinAlgWarning: Ill-conditioned matrix (rcond=3.55851e-19): result may not be accurate.\n",
      "  aa = solve(eye2k + (alpha * tau) * VU, VX)\n",
      "/Users/lianama/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/lianama/anaconda3/lib/python3.10/site-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "\n",
      "Results for Scaled Gradient Projection Method \n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "   Obj. function = 3.891533e+05\n",
      "\n",
      "   Gradient norm = 1.229389e+01 \n",
      "\n",
      "   ||X^T*X-I||_F = 4.97e-16\n",
      "\n",
      "   Iteration number = 3000\n",
      "\n",
      "   Cpu time (secs) = 5.9020\n",
      "\n",
      "   Number of evaluation(Obj. func) = 4123\n",
      "\n",
      "Training Linear Model\n",
      "coefficients:  [ 0.122791602837945 10.507565601567029]\n",
      "intercept:  189.8920634920635\n",
      "R-squared:  0.11909860569817732\n",
      "[[ 0.464681916533837  0.01165588773159  -0.000580249559588\n",
      "  -0.010579890501132 -0.000872963064333  0.286681505968123\n",
      "  -0.005675816524388]\n",
      " [ 0.01165588773159   0.791787840908798 -0.002603007649836\n",
      "   0.37084947439795   0.007108920179656  0.006310329557888\n",
      "   0.089000357272796]\n",
      " [-0.000580249559588 -0.002603007649836  0.000009189659409\n",
      "  -0.00120045762786  -0.000022230067966 -0.000355099884764\n",
      "  -0.000284438899952]\n",
      " [-0.010579890501132  0.37084947439795  -0.00120045762786\n",
      "   0.174248494940151  0.003363359353529 -0.006940099145292\n",
      "   0.04192629560691 ]\n",
      " [-0.000872963064333  0.007108920179656 -0.000022230067966\n",
      "   0.003363359353529  0.0000658836156   -0.000546501260296\n",
      "   0.00081377597409 ]\n",
      " [ 0.286681505968123  0.006310329557888 -0.000355099884764\n",
      "  -0.006940099145292 -0.000546501260296  0.176866665729155\n",
      "  -0.003600832185886]\n",
      " [-0.005675816524388  0.089000357272796 -0.000284438899952\n",
      "   0.04192629560691   0.00081377597409  -0.003600832185886\n",
      "   0.010109088328271]\n",
      " [ 0.017601446962118 -0.086891478702834  0.000263628879276\n",
      "  -0.041349270835399 -0.000819875268418  0.010956233528559\n",
      "  -0.010050929555861]\n",
      " [-0.029542196037386  0.107254002878795 -0.000316290166182\n",
      "   0.051309115701946  0.001028457907689 -0.018345965768928\n",
      "   0.012523855504583]\n",
      " [-0.295484343771835 -0.006813133936706  0.000367014237971\n",
      "   0.007008299881228  0.000560497890961 -0.182297186921644\n",
      "   0.003676593493984]\n",
      " [ 0.02012360201035  -0.002099413351618 -0.000016611845278\n",
      "  -0.001679220104512 -0.00006126657978   0.012417980518161\n",
      "  -0.000539096162721]\n",
      " [-0.278184705929357 -0.008490626232786  0.000352317208021\n",
      "   0.005624418436675  0.000508975867452 -0.17162197504624\n",
      "   0.003227487402976]]\n",
      "This is the norm of the difference\n",
      "0.2960301060769725\n",
      "statsmodels\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                     12   R-squared (uncentered):                   0.057\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.051\n",
      "Method:                 Least Squares   F-statistic:                              9.505\n",
      "Date:                Thu, 04 Jan 2024   Prob (F-statistic):                    9.83e-05\n",
      "Time:                        11:54:18   Log-Likelihood:                         -2193.5\n",
      "No. Observations:                 315   AIC:                                      4391.\n",
      "Df Residuals:                     313   BIC:                                      4399.\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.1228      0.053      2.321      0.021       0.019       0.227\n",
      "x2            10.5076      2.477      4.242      0.000       5.634      15.382\n",
      "==============================================================================\n",
      "Omnibus:                      249.610   Durbin-Watson:                   0.785\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3468.423\n",
      "Skew:                           3.266   Prob(JB):                         0.00\n",
      "Kurtosis:                      17.886   Cond. No.                         49.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import cir\n",
    "from cir import CIR\n",
    "from importlib import reload\n",
    "reload(cir)\n",
    "\n",
    "\n",
    "data = pd.read_table('Retinol.txt', header=None, delim_whitespace=True)\n",
    "data = data.iloc[:, :]\n",
    "\n",
    "# foreground data \n",
    "fg = data.iloc[:, :12].dropna()\n",
    "\n",
    "# foreground response (continuous)\n",
    "Y = data.iloc[:, 12]\n",
    "n, p = fg.shape  # foreground sample size\n",
    "X = fg - np.mean(fg, axis=0)\n",
    "X = X.values\n",
    "\n",
    "# foreground slices \n",
    "L = 10\n",
    "partition = np.linspace(min(Y), max(Y), L)\n",
    "labels = np.zeros(n)\n",
    "for i in range(n):\n",
    "    labels[i] = max(np.where(Y.iloc[i] >= partition)[0]) + 1\n",
    "\n",
    "# background data \n",
    "bg = data.iloc[:, :12].dropna()\n",
    "m, p = bg.shape     # background sample size\n",
    "\n",
    "# background data\n",
    "Yt = data.iloc[:, 13]\n",
    "Lt = 10\n",
    "partitiont = np.linspace(min(Yt), max(Yt), Lt)\n",
    "labelst = np.zeros(m)\n",
    "for i in range(m):\n",
    "    labelst[i] = max(np.where(Yt.iloc[i] >= partitiont)[0]) + 1\n",
    "\n",
    "d = 2\n",
    "alpha = 0.1\n",
    "\n",
    "\n",
    "V_CIR = CIR(fg,labels,bg,labelst,alpha,d)\n",
    "vvt = V_CIR @ V_CIR.T\n",
    "\n",
    "X_CIR = X @ V_CIR\n",
    "# print(V_CIR[:10, :])\n",
    "\n",
    "print(\"Training Linear Model\")\n",
    "model_CIR_LM = LinearRegression().fit(X_CIR, Y)\n",
    "print(\"coefficients: \", model_CIR_LM.coef_)\n",
    "print(\"intercept: \", model_CIR_LM.intercept_)\n",
    "print(\"R-squared: \", model_CIR_LM.score(X_CIR, Y))\n",
    "\n",
    "\n",
    "\n",
    "m1 = [[0.532599608105052,   0.004620083626876,  -0.000320112347451,  -0.006601571813602,  -0.000499345812859,   0.295110986421280,  -0.005625130202443],\n",
    "   [0.004620083626876,   0.926065049338340,  -0.000978627564536,   0.221573065829260,   0.004981206774528,   0.000999866145938,   0.078676661438859],\n",
    "  [-0.000320112347451,  -0.000978627564536,   0.000001220756928,  -0.000229587592840,  -0.000004953664970,  -0.000175728731562,  -0.000079580448973],\n",
    "  [-0.006601571813602,   0.221573065829260,  -0.000229587592840,   0.053125756655810,   0.001199404003959,  -0.004031287483785,   0.018911493104884],\n",
    "  [-0.000499345812859,   0.004981206774528,  -0.000004953664970,   0.001199404003959,   0.000027309337619,  -0.000285084491660,   0.000429116469334],\n",
    "  [0.295110986421280 ,  0.000999866145938 , -0.000175728731562 , -0.004031287483785 , -0.000285084491660,   0.163522264826441,  -0.003249489741347],\n",
    "  [-0.005625130202443,   0.078676661438859,  -0.000079580448973,   0.018911493104884,   0.000429116469334,  -0.003249489741347,   0.006752208134958],\n",
    "   [0.010839350364305,  -0.064090742373393,   0.000061123442157,  -0.015496025558275,  -0.000355720894400,   0.006114167969579,  -0.005571111050421],\n",
    "  [-0.010753209254731,   0.094933481291968,  -0.000093676693721,   0.022876530750223,   0.000521687418020,  -0.006118397967805,   0.008192214667748],\n",
    "  [-0.282957166594681,  -0.001048554700505,   0.000168586240285,   0.003843755046652,   0.000272859775825,  -0.156787629668804,   0.003108023113917],\n",
    "   [0.015239189508293,  -0.001950955622589,  -0.000006964089265,  -0.000687460621746,  -0.000025502974935,   0.008447474162690,  -0.000338048665003],\n",
    "  [-0.284990767155745,  -0.003305043920851,   0.000172167822695,   0.003333126351607,   0.000262712879579,  -0.157910666507893,   0.002939166922469]]\n",
    "\n",
    "\n",
    "\n",
    "VVt_s = vvt[:12, :7]\n",
    "print(VVt_s)\n",
    "norm = np.linalg.norm(VVt_s-m1, ord='fro')\n",
    "print(\"This is the norm of the difference\")\n",
    "print(norm)\n",
    "\n",
    "\n",
    "\n",
    "# # tuning parameter\n",
    "# alpha = 1.5\n",
    "# d = 2\n",
    "\n",
    "# # CIR \n",
    "# print(\"CIR......\")\n",
    "# V_CIR = CIR(fg,Y,bg,Yt,alpha,d)\n",
    "# X_CIR = X @ V_CIR\n",
    "\n",
    "# # colors = 228/255\n",
    "# markers = 'o'\n",
    "# colors = [[228/255, 26/255, 28/255],\n",
    "#           [55/255, 126/255, 184/255],\n",
    "#           [77/255, 175/255, 74/255],\n",
    "#           [152/255, 78/255, 163/255],\n",
    "#           [255/255, 127/255, 0/255],\n",
    "#           [255/255, 255/255, 51/255],\n",
    "#           [166/255, 86/255, 40/255],\n",
    "#           [247/255, 129/255, 191/255],\n",
    "#           [153/255, 153/255, 153/255]]\n",
    "\n",
    "\n",
    "# markers = ['o', 's', 'p', 'o', 's', 'p', 'o', 's', 'p']\n",
    "\n",
    "# for l in range(L):\n",
    "#     idx = np.where(Y == labels[l])[0]\n",
    "#     X_curr = X_CIR[idx, :]\n",
    "#     plt.scatter(X_curr[:, 0], X_curr[:, 1], s=100, c=colors, marker=markers)\n",
    "# # plt.hold(False)\n",
    "# plt.title('CIR', fontsize=32)\n",
    "# plt.xticks(fontsize=22)\n",
    "# plt.yticks(fontsize=22)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
